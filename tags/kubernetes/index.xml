<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on Linuzb&#39; 的博客</title>
    <link>https://linuzb.github.io/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on Linuzb&#39; 的博客</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>© Copyright notice</copyright>
    <lastBuildDate>Sun, 28 Apr 2024 16:33:37 +0800</lastBuildDate>
    <atom:link href="https://linuzb.github.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Jupyterhub Userguide</title>
      <link>https://linuzb.github.io/2024/04/jupyterhub-userguide/</link>
      <pubDate>Sun, 28 Apr 2024 16:33:37 +0800</pubDate>
      <guid>https://linuzb.github.io/2024/04/jupyterhub-userguide/</guid>
      <description>前置准备 本文是 jupyterhub on kubernetes 的使用文档，本文描述的环境基于 jupyterhub on kubernetes&#xA;在上述文档中，我们部署的 kubernetes master 节点 nodeIP 为 172.16.0.100, 因此以下教程中使用的访问 ip 都是 172.16.0.100&#xA;环境准备 内网访问 可以访问内网的浏览器&#xA;登录 使用浏览器访问 http://172.16.0.100:30080/ 认证 点击 Singn in with Github，然后在 github 页面授权&#xA;说明：&#xA;这里仅使用 github oauth 做认证鉴权，暂无其它依赖，原理课参考文档 Authorizing OAuth apps - GitHub Docs github 账号的用户名需要为全字母及数字，暂不支持非字母数字之外的其他符号 应用选择 登录完成之后就会进入一个应用服务页面&#xA;选择一个合适的应用环境，然后点击底部的 start 按钮，即可进入环境 自定义应用 TODO： 待补充&#xA;应用环境介绍 功能介绍 界面简介 应用创建完成后，就会跳转到jupyterlab页面 介绍一下主要功能&#xA;启动一个luncher，即页面右侧部分，在 luncher 中可以打开各种工具 上传文件按钮，点击后弹出一个对话框，选择需要上传到文件即可。如果想上传一个目录，可以先在本地将目录打包成一个压缩包，然后上传。上传前可以先按照3. 切换到对应的工作目录。 工作目录，双击可打开文件以及文件夹。上传文件以及打开vscode都是以工作目录为基础，例如，当前工作目录为~/Projects/data, 则上传目标路径即为~/Projects/data 新建一个jupyter notebook 以工作目录为基础打开vscode 打开一个terminal，可执行linux命令 vscode 打开方式：在luncher 中点击vscode 图标即可打开</description>
    </item>
    <item>
      <title>Jupyterhub on Kubernetes</title>
      <link>https://linuzb.github.io/2024/04/jupyterhub-on-kubernetes/</link>
      <pubDate>Sun, 28 Apr 2024 15:57:55 +0800</pubDate>
      <guid>https://linuzb.github.io/2024/04/jupyterhub-on-kubernetes/</guid>
      <description>前置准备 首先需要部署 kubernetes 集群，参考k8s deploy Helm | Installing Helm 安装 helm 存储：Longhorn provider 部署 Longhorn 参考 Longhorn deploy&#xA;接入 github oauth 本文使用 github oauth 作为认证方式，首先我们需要提前注册一个 GitHub OAuth 应用程序，请参阅 GitHub 有关注册应用程序的官方文档 registering an app.&#xA;然后我们得到三个信息&#xA;client-id client-secret oauthCallbackUrl 为了避免在配置中明文保存密码，我们将以上信息通过 secret 的形式存储在 Kubernetes 中，可以使用挂载 secret 的形式使用 secret 变量。&#xA;创建secret 接下来我们给 client-id 和 client-secret 创建secret&#xA;1 2 3 echo -n &amp;#34;client-id&amp;#34; | base64 echo -n &amp;#34;client-secret&amp;#34; | base64 echo -n &amp;#34;oauthCallbackUrl&amp;#34; | base64 将以上结果填充到用于创建 secret 的 yaml 中</description>
    </item>
    <item>
      <title>Kubernetes 部署 longhorn 存储</title>
      <link>https://linuzb.github.io/2024/04/kubernetes-%E9%83%A8%E7%BD%B2-longhorn-%E5%AD%98%E5%82%A8/</link>
      <pubDate>Sun, 28 Apr 2024 15:46:48 +0800</pubDate>
      <guid>https://linuzb.github.io/2024/04/kubernetes-%E9%83%A8%E7%BD%B2-longhorn-%E5%AD%98%E5%82%A8/</guid>
      <description>背景 longhorn 是基于 Kubernetes 构建的云原生分布式存储&#xA;依赖 Installation Requirements&#xA;ubuntu 安装依赖 运行以下脚本，检查是否满足依赖&#xA;1 curl -sSfL https://raw.githubusercontent.com/longhorn/longhorn/v1.6.1/scripts/environment_check.sh | bash 如果缺少依赖，需要安装依赖，例如&#xA;1 2 apt-get install open-iscsi apt-get install nfs-common kubectl 安装及 kubeconfig 配置&#xA;部署 helm Longhorn | Documentation&#xA;1 2 3 4 5 6 helm pull longhorn/longhorn --version 1.6.1 helm upgrade --install longhorn ./longhorn \ --namespace longhorn-system \ --create-namespace \ --version 1.6.1 \ --values config.yaml config.yaml&#xA;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 defaultSettings: # 配置默认数据存放地址 defaultDataPath: /data/longhorn service: ui: # -- Service type for Longhorn UI.</description>
    </item>
    <item>
      <title>kubernetes 监控部署</title>
      <link>https://linuzb.github.io/2024/04/kubernetes-%E7%9B%91%E6%8E%A7%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Sun, 28 Apr 2024 15:09:33 +0800</pubDate>
      <guid>https://linuzb.github.io/2024/04/kubernetes-%E7%9B%91%E6%8E%A7%E9%83%A8%E7%BD%B2/</guid>
      <description>准备 首先需要部署 kubernetes 集群，参考k8s deploy helm 安装 prometheus 软件栈 Setting up Prometheus — NVIDIA GPU Telemetry 1.0.0 documentation&#xA;使用以下命令安装 prometheus&#xA;1 2 3 4 5 6 7 8 9 helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \ --namespace prometheus \ --create-namespace \ --set prometheus.service.type=NodePort \ --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \ --set prometheusOperator.admissionWebhooks.patch.image.registry=registry.cn-hangzhou.aliyuncs.com \ --set prometheusOperator.admissionWebhooks.patch.image.repository=linuzb/kube-webhook-certgen \ --set kube-state-metrics.image.registry=registry.cn-hangzhou.aliyuncs.com \ --set kube-state-metrics.image.repository=linuzb/kube-state-metrics 安装 GPU 监控 DCGM 1 2 3 4 helm upgrade --install \ dcgm-exporter \ gpu-helm-charts/dcgm-exporter \ --values config.</description>
    </item>
    <item>
      <title>Kubespray 部署 kubernetes</title>
      <link>https://linuzb.github.io/2024/04/kubespray-%E9%83%A8%E7%BD%B2-kubernetes/</link>
      <pubDate>Sun, 28 Apr 2024 10:06:36 +0800</pubDate>
      <guid>https://linuzb.github.io/2024/04/kubespray-%E9%83%A8%E7%BD%B2-kubernetes/</guid>
      <description>准备 本文介绍中共使用了四台物理机, 其中一台用户部署 k8s 的机器，另外三台作为 kubernetes 的节点&#xA;机器 ip 系统 用户名 备注 部署机 任意 Ubuntu linuzb 部署k8s机器，非k8s集群节点 kube-master-100 172.16.0.100 Ubutnu linuzb 初始化 k8s master 节点 kube-node-117 172.16.0.117 Ubutnu linuzb 初始化 k8s node kube-node-114 172.16.0.114 Ubutnu linuzb 后续加入的 k8s node kubespray 配置 自定义配置 1 2 3 4 git clone https://github.com/kubernetes-sigs/kubespray cd kubespray # 拷贝集群清单 cp -rfp inventory/sample inventory/mycluster inventory inventory.ini&#xA;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # ## Configure &amp;#39;ip&amp;#39; variable to bind kubernetes services on a # ## different ip than the default iface # ## We should set etcd_member_name for etcd cluster.</description>
    </item>
  </channel>
</rss>
